{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3e975b59-5ddf-47b8-823e-8d71caf89193",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importar librerías necesarias\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Cargar el dataset principal de solicitudes de adelanto en efectivo\n",
    "cr = pd.read_csv('../project_dataset/extract - cash request - data analyst.csv')\n",
    "# Inspeccionar la estructura y el tipo de datos de 'cash_request'\n",
    "#cr.info()\n",
    "# Crear una copia del DataFrame para preservar el original\n",
    "credit_requests = cr.copy()\n",
    "# Cargar el dataset de tarifas o fees para análisis de cohortes de tarifas\n",
    "fs = pd.read_csv('../project_dataset/extract - fees - data analyst - .csv')\n",
    "#fs.head()\n",
    "# Crear una copia del DataFrame para preservar el original\n",
    "fees = fs.copy()\n",
    "# Clean `credit_requests`\n",
    "# Rellenar valores nulos en 'user_id' usando 'deleted_account_id' (clientes transferidos de cuentas eliminadas)\n",
    "cash_requests = credit_requests\n",
    "#cash_request.fillna({\"user_id\": cash_request[\"deleted_account_id\"]}, inplace=True)\n",
    "\n",
    "# 2. Estandarización de formatos\n",
    "# Convert datetime columns to pandas datetime\n",
    "datetime_columns = ['created_at', 'updated_at', 'moderated_at', 'reimbursement_date', 'money_back_date', 'send_at', 'reco_creation', 'reco_last_update']\n",
    "for col in datetime_columns:\n",
    "    cash_request[col] = pd.to_datetime(cash_request[col], errors='coerce')\n",
    "    cash_request[col] = cash_request[col].dt.tz_localize(None)\n",
    "    credit_requests[col] = pd.to_datetime(cash_request[col], errors='coerce')\n",
    "    credit_requests[col] = credit_requests[col].dt.tz_localize(None)\n",
    "\n",
    "\n",
    "# Fill missing `user_id` with -1 (or another placeholder)\n",
    "credit_requests['user_id'] = credit_requests['user_id'].fillna(-1)\n",
    "\n",
    "# 1. Manejo de valores faltantes\n",
    "# - For simplicity: drop rows where `cash_request_id` is NaN (primary key related)\n",
    "# - Impute 'category' with 'Unknown', keep `paid_at`, `from_date`, `to_date` for further filtering\n",
    "data_cleaned = fees.dropna(subset=['cash_request_id'])\n",
    "data_cleaned['category'] = data_cleaned['category'].fillna('Unknown')\n",
    "\n",
    "# 2. Estandarización de formatos\n",
    "# Convert datetime columns to pandas datetime\n",
    "datetime_columns = ['created_at', 'updated_at', 'paid_at', 'from_date', 'to_date']\n",
    "for col in datetime_columns:\n",
    "    data_cleaned[col] = pd.to_datetime(data_cleaned[col], errors='coerce')\n",
    "    data_cleaned[col] = data_cleaned[col].dt.tz_localize(None)\n",
    "\n",
    "# Standardize column names\n",
    "data_cleaned.columns = data_cleaned.columns.str.lower().str.replace(' ', '_')\n",
    "\n",
    "# 3. Filtrado de datos irrelevantes\n",
    "# Remove rows with invalid or irrelevant `status`\n",
    "valid_statuses = ['accepted', 'rejected', 'pending']\n",
    "data_cleaned = data_cleaned[data_cleaned['status'].isin(valid_statuses)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b79d98a3-1af9-40e1-881b-8202475f1fe4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 23970 entries, 0 to 23969\n",
      "Data columns (total 19 columns):\n",
      " #   Column                      Non-Null Count  Dtype         \n",
      "---  ------                      --------------  -----         \n",
      " 0   id                          23970 non-null  int64         \n",
      " 1   amount                      23970 non-null  float64       \n",
      " 2   status                      23970 non-null  object        \n",
      " 3   created_at                  23970 non-null  datetime64[ns]\n",
      " 4   updated_at                  23970 non-null  datetime64[ns]\n",
      " 5   user_id                     23970 non-null  float64       \n",
      " 6   moderated_at                15912 non-null  datetime64[ns]\n",
      " 7   deleted_account_id          2104 non-null   float64       \n",
      " 8   reimbursement_date          3050 non-null   datetime64[ns]\n",
      " 9   cash_request_received_date  16289 non-null  object        \n",
      " 10  money_back_date             12040 non-null  datetime64[ns]\n",
      " 11  transfer_type               23970 non-null  object        \n",
      " 12  send_at                     16466 non-null  datetime64[ns]\n",
      " 13  recovery_status             3330 non-null   object        \n",
      " 14  reco_creation               3330 non-null   datetime64[ns]\n",
      " 15  reco_last_update            3330 non-null   datetime64[ns]\n",
      " 16  cash_request_id             12933 non-null  float64       \n",
      " 17  total_fee_amount            23970 non-null  float64       \n",
      " 18  fee_count                   23970 non-null  float64       \n",
      "dtypes: datetime64[ns](8), float64(6), int64(1), object(4)\n",
      "memory usage: 3.5+ MB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(None,\n",
       "      id  amount    status                 created_at  \\\n",
       " 0     5   100.0  rejected 2019-12-10 19:05:21.596873   \n",
       " 1    70   100.0  rejected 2019-12-10 19:50:12.347780   \n",
       " 2     7   100.0  rejected 2019-12-10 19:13:35.825460   \n",
       " 3    10    99.0  rejected 2019-12-10 19:16:10.880172   \n",
       " 4  1594   100.0  rejected 2020-05-06 09:59:38.877376   \n",
       " \n",
       "                   updated_at  user_id               moderated_at  \\\n",
       " 0 2019-12-11 16:47:42.407830    804.0 2019-12-11 16:47:42.405646   \n",
       " 1 2019-12-11 14:24:22.900054    231.0 2019-12-11 14:24:22.897988   \n",
       " 2 2019-12-11 09:46:59.779773    191.0 2019-12-11 09:46:59.777728   \n",
       " 3 2019-12-18 14:26:18.136163    761.0 2019-12-18 14:26:18.128407   \n",
       " 4 2020-05-07 09:21:55.340080   7686.0 2020-05-07 09:21:55.320193   \n",
       " \n",
       "    deleted_account_id         reimbursement_date cash_request_received_date  \\\n",
       " 0                 NaN 2020-01-09 19:05:21.596363                        NaN   \n",
       " 1                 NaN 2020-01-09 19:50:12.347780                        NaN   \n",
       " 2                 NaN 2020-01-09 19:13:35.825041                        NaN   \n",
       " 3                 NaN 2020-01-09 19:16:10.879606                        NaN   \n",
       " 4                 NaN                        NaT                        NaN   \n",
       " \n",
       "   money_back_date transfer_type send_at recovery_status reco_creation  \\\n",
       " 0             NaT       regular     NaT             NaN           NaT   \n",
       " 1             NaT       regular     NaT             NaN           NaT   \n",
       " 2             NaT       regular     NaT             NaN           NaT   \n",
       " 3             NaT       regular     NaT             NaN           NaT   \n",
       " 4             NaT       regular     NaT             NaN           NaT   \n",
       " \n",
       "   reco_last_update  cash_request_id  total_fee_amount  fee_count  \n",
       " 0              NaT              NaN               0.0        0.0  \n",
       " 1              NaT              NaN               0.0        0.0  \n",
       " 2              NaT              NaN               0.0        0.0  \n",
       " 3              NaT              NaN               0.0        0.0  \n",
       " 4              NaT              NaN               0.0        0.0  )"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Step 1: Merge datasets using cash_request_id\n",
    "merged_data = fees.merge(cash_requests, left_on='cash_request_id', right_on='id', how='right', suffixes=('_fees', '_cash'))\n",
    "\n",
    "# Step 2: Aggregate fees data for each cash_request_id (total_amount, count of fees)\n",
    "fees_aggregated = fees.groupby('cash_request_id').agg(\n",
    "    total_fee_amount=('total_amount', 'sum'),\n",
    "    fee_count=('id', 'count')\n",
    ").reset_index()\n",
    "\n",
    "# Step 3: Merge aggregated fees back to cash_requests\n",
    "cash_requests_with_fees = cash_requests.merge(fees_aggregated, left_on='id', right_on='cash_request_id', how='left')\n",
    "\n",
    "# Replace NaN values in fee columns for cash requests with no fees\n",
    "cash_requests_with_fees['total_fee_amount'] = cash_requests_with_fees['total_fee_amount'].fillna(0)\n",
    "cash_requests_with_fees['fee_count'] = cash_requests_with_fees['fee_count'].fillna(0)\n",
    "\n",
    "# Step 4: Inspect the resulting dataframe\n",
    "cash_requests_with_fees.info(), cash_requests_with_fees.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ffdb462e-96a9-42b2-867a-06243fe72693",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(706.2246770291208,\n",
       " 0.006823776482972832,\n",
       " array([-6.37960232, 29.23816766]),\n",
       " 84.55785556497335)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "import numpy as np\n",
    "\n",
    "# Step 1: Define features and target variable\n",
    "X = cash_requests_with_fees[['total_fee_amount', 'fee_count']]\n",
    "y = cash_requests_with_fees['amount']\n",
    "\n",
    "# Step 2: Split data into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Step 3: Train the regression model\n",
    "model = LinearRegression()\n",
    "\n",
    "# Filter fees where 'paid_at' is not null\n",
    "fees_paid = fees[fees['paid_at'].notnull()]\n",
    "\n",
    "# Re-aggregate fees data for each cash_request_id based on the filtered data\n",
    "fees_paid_aggregated = fees_paid.groupby('cash_request_id').agg(\n",
    "    total_fee_amount=('total_amount', 'sum'),\n",
    "    fee_count=('id', 'count')\n",
    ").reset_index()\n",
    "\n",
    "# Merge the updated aggregated fees back to cash_requests\n",
    "cash_requests_with_paid_fees = cash_requests.merge(fees_paid_aggregated, left_on='id', right_on='cash_request_id', how='left')\n",
    "\n",
    "# Replace NaN values in fee columns for cash requests with no fees\n",
    "cash_requests_with_paid_fees['total_fee_amount'] = cash_requests_with_paid_fees['total_fee_amount'].fillna(0)\n",
    "cash_requests_with_paid_fees['fee_count'] = cash_requests_with_paid_fees['fee_count'].fillna(0)\n",
    "\n",
    "# Redefine features and target variable\n",
    "X = cash_requests_with_paid_fees[['total_fee_amount', 'fee_count']]\n",
    "y = cash_requests_with_paid_fees['amount']\n",
    "\n",
    "# Split the data into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Retrain the regression model\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "mse_paid = mean_squared_error(y_test, y_pred)\n",
    "r2_paid = r2_score(y_test, y_pred)\n",
    "\n",
    "# Updated coefficients and intercept\n",
    "coefficients_paid = model.coef_\n",
    "intercept_paid = model.intercept_\n",
    "\n",
    "mse_paid, r2_paid, coefficients_paid, intercept_paid\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a6015194-f94a-456c-9e76-a8a39e9412df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'alpha': 1000}, 0.00462360167993423, 706.2261823677953, 0.006821659498635446)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Define the Ridge model\n",
    "ridge = Ridge()\n",
    "\n",
    "# Define the hyperparameter grid\n",
    "param_grid = {\n",
    "    'alpha': [0.01, 0.1, 1, 10, 100, 1000]  # Test different regularization strengths\n",
    "}\n",
    "\n",
    "# Perform Grid Search with 5-fold Cross-Validation\n",
    "grid_search_ridge = GridSearchCV(ridge, param_grid, cv=5, scoring='r2')\n",
    "grid_search_ridge.fit(X_train, y_train)\n",
    "\n",
    "# Extract the best parameters and score\n",
    "ridge_best_params = grid_search_ridge.best_params_\n",
    "ridge_best_score = grid_search_ridge.best_score_\n",
    "\n",
    "# Fit the final model using the best parameters\n",
    "ridge_final_model = Ridge(alpha=ridge_best_params['alpha'])\n",
    "ridge_final_model.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate on the test set\n",
    "y_test_pred = ridge_final_model.predict(X_test)\n",
    "ridge_mse = mean_squared_error(y_test, y_test_pred)\n",
    "ridge_r2 = r2_score(y_test, y_test_pred)\n",
    "\n",
    "ridge_best_params, ridge_best_score, ridge_mse, ridge_r2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "14007ad4-3e05-4164-9aa7-b5b9ab05e341",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'alpha': 0.1}, 0.00462302065911786, 706.2369037914455, 0.006806581771393816)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import Lasso\n",
    "\n",
    "# Define the Lasso model\n",
    "lasso = Lasso(max_iter=10000)  # Increase max_iter for convergence if needed\n",
    "\n",
    "# Define the hyperparameter grid for Lasso\n",
    "param_grid_lasso = {\n",
    "    'alpha': [0.01, 0.1, 1, 10, 100, 1000]  # Regularization strengths to explore\n",
    "}\n",
    "\n",
    "# Perform Grid Search with 5-fold Cross-Validation for Lasso\n",
    "grid_search_lasso = GridSearchCV(lasso, param_grid_lasso, cv=5, scoring='r2')\n",
    "grid_search_lasso.fit(X_train, y_train)\n",
    "\n",
    "# Extract the best parameters and score for Lasso\n",
    "lasso_best_params = grid_search_lasso.best_params_\n",
    "lasso_best_score = grid_search_lasso.best_score_\n",
    "\n",
    "# Fit the final Lasso model using the best parameters\n",
    "lasso_final_model = Lasso(alpha=lasso_best_params['alpha'], max_iter=10000)\n",
    "lasso_final_model.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate on the test set\n",
    "y_test_pred_lasso = lasso_final_model.predict(X_test)\n",
    "lasso_mse = mean_squared_error(y_test, y_test_pred_lasso)\n",
    "lasso_r2 = r2_score(y_test, y_test_pred_lasso)\n",
    "\n",
    "lasso_best_params, lasso_best_score, lasso_mse, lasso_r2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcf7a2f0-211f-40ac-881e-360e2f12d34f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
